{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12036716,"sourceType":"datasetVersion","datasetId":7573927}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ---------------------------------------\n# Gerekli Kütüphaneler\n# ---------------------------------------\nimport os\nimport glob\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport nibabel as nib\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.nn import CrossEntropyLoss\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom collections import Counter\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torchvision.models.video as video_models\nfrom torch.amp import autocast, GradScaler\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nimport joblib\nimport pandas as pd\n\n# ---------------------------------------\n# CUDA ve CUDNN Ayarları\n# ---------------------------------------\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.deterministic = False\nprint(f\"Using device: {DEVICE}\")\n\n# ---------------------------------------\n# 1) Dataset Dizini ve Sınıf Etiketleri\n# ---------------------------------------\nDATA_DIR = '/kaggle/input/adniunpreprocessed'  # Ham NIfTI klasörünüz\nclasses = {'CN': 0, 'MCI': 1, 'AD': 2}\n\n# ---------------------------------------\n# 2) Dosya Toplama ve Filtreleme\n# ---------------------------------------\npattern = os.path.join(DATA_DIR, '**', '*.nii*')\nall_files = glob.glob(pattern, recursive=True)\nvalid_paths, valid_labels = [], []\n\nfor fp in all_files:\n    parent = os.path.basename(os.path.dirname(fp))\n    if parent not in classes:\n        continue\n    if os.path.getsize(fp) == 0:\n        continue\n    valid_paths.append(fp)\n    valid_labels.append(classes[parent])\n\n# İkinci filtre: sadece açılabilen NIfTI\nclean_paths, clean_labels = [], []\nfor path, label in zip(valid_paths, valid_labels):\n    try:\n        _ = nib.load(path)\n        clean_paths.append(path)\n        clean_labels.append(label)\n    except:\n        continue\n\nvalid_paths  = clean_paths\nvalid_labels = clean_labels\nprint(f\"Total sample sayısı: {len(valid_paths)}\")\nprint(\"Sınıf dağılımı:\", {c: valid_labels.count(classes[c]) for c in classes})\n\n# ---------------------------------------\n# 3) Train/Test Split\n# ---------------------------------------\npaths_train, paths_test, labels_train, labels_test = train_test_split(\n    valid_paths, valid_labels, test_size=0.20, stratify=valid_labels, random_state=42\n)\nprint(f\"Train / Test sayıları: {len(paths_train)}/{len(paths_test)}\")\n\n# ---------------------------------------\n# 4) Model Sınıfı\n# ---------------------------------------\nclass ResNet3DClassifier(nn.Module):\n    def __init__(self, num_classes=3, pretrained=True):\n        super().__init__()\n        # Video ResNet18 (r3d_18) kullanıyoruz\n        self.resnet3d = video_models.r3d_18(weights='DEFAULT' if pretrained else None)\n        \n        # İlk conv katmanını tek kanallı MR hacmi için güncelle\n        self.resnet3d.stem[0] = nn.Conv3d(\n            in_channels=1, out_channels=64, kernel_size=(3,7,7),\n            stride=(1,2,2), padding=(1,3,3), bias=False\n        )\n        \n        # Dropout ekle\n        self.dropout = nn.Dropout(0.5)\n        \n        # Son fc katmanını yeniden tanımla\n        self.resnet3d.fc = nn.Sequential(\n            nn.Linear(self.resnet3d.fc.in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.resnet3d(x)\n        x = self.dropout(x)\n        return x\n    \n    def extract_features(self, x):\n        # ResNet'in son katmanından önceki özellikleri çıkar\n        x = self.resnet3d.stem(x)\n        x = self.resnet3d.layer1(x)\n        x = self.resnet3d.layer2(x)\n        x = self.resnet3d.layer3(x)\n        x = self.resnet3d.layer4(x)\n        x = self.resnet3d.avgpool(x)\n        x = torch.flatten(x, 1)\n        return x\n\n# ---------------------------------------\n# 5) Dataset Sınıfı\n# ---------------------------------------\nclass ADNI_ResNet3D_Dataset(Dataset):\n    def __init__(self, paths, labels, \n                 target_depth=64, target_height=112, target_width=112,\n                 is_training=True):\n        self.paths = paths\n        self.labels = labels\n        self.d = target_depth\n        self.h = target_height\n        self.w = target_width\n        self.is_training = is_training\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        # 1) Load NIfTI\n        path = self.paths[idx]\n        img = nib.load(path).get_fdata().astype(np.float32)\n\n        # 2) Robust normalization (%1-%99 persentil arasını [0,1])\n        p1, p99 = np.percentile(img, (1, 99))\n        img = np.clip(img, p1, p99)\n        img = (img - p1) / (p99 - p1 + 1e-6)\n\n        # 3) Center-crop veya pad 3D hacim → target (D x H x W)\n        D, H, W = img.shape\n        \n        # Depth (z ekseni) orta bölgeden target_depth al\n        cd = D // 2\n        hd = self.d // 2\n        start_d = max(cd - hd, 0)\n        end_d = start_d + self.d\n        if end_d > D:\n            end_d = D\n            start_d = D - self.d\n        patch = img[start_d:end_d, :, :]\n\n        # Yükseklik ve genişlik için merkezden al veya pad\n        ch = H // 2\n        hh = self.h // 2\n        start_h = max(ch - hh, 0)\n        end_h = start_h + self.h\n        if end_h > H:\n            end_h = H\n            start_h = H - self.h\n        patch = patch[:, start_h:end_h, :]\n\n        cw = W // 2\n        hw = self.w // 2\n        start_w = max(cw - hw, 0)\n        end_w = start_w + self.w\n        if end_w > W:\n            end_w = W\n            start_w = W - self.w\n        patch = patch[:, :, start_w:end_w]\n\n        # Eğer patch boyutları eksikse pad et\n        pd, ph, pw = patch.shape\n        if pd != self.d or ph != self.h or pw != self.w:\n            padded = np.zeros((self.d, self.h, self.w), dtype=np.float32)\n            sd = (self.d - pd) // 2\n            sh = (self.h - ph) // 2\n            sw = (self.w - pw) // 2\n            padded[sd:sd+pd, sh:sh+ph, sw:sw+pw] = patch\n            patch = padded\n\n        # 4) Tensor'a dönüştür ve kanal ekseni ekle: (1, D, H, W)\n        img_tensor = torch.from_numpy(patch).unsqueeze(0)\n\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return img_tensor, label\n\n# ---------------------------------------\n# 6) Dataset ve DataLoader\n# ---------------------------------------\ntrain_ds = ADNI_ResNet3D_Dataset(\n    paths_train, labels_train,\n    target_depth=64, target_height=112, target_width=112,\n    is_training=True\n)\n\ntest_ds = ADNI_ResNet3D_Dataset(\n    paths_test, labels_test,\n    target_depth=64, target_height=112, target_width=112,\n    is_training=False\n)\n\nbatch_size = 2\ntrain_loader = DataLoader(\n    train_ds, batch_size=batch_size,\n    shuffle=True, num_workers=2,\n    pin_memory=True, prefetch_factor=2\n)\n\ntest_loader = DataLoader(\n    test_ds, batch_size=batch_size,\n    shuffle=False, num_workers=2,\n    pin_memory=True, prefetch_factor=2\n)\n\n# ---------------------------------------\n# 8) Özellik Çıkarma ve ML Algoritmaları\n# ---------------------------------------\ndef extract_features_and_train_ml(model, data_loader, device):\n    model.eval()\n    all_features = []\n    all_labels = []\n    \n    # Özellik çıkarma sürecini optimize et\n    with torch.no_grad():\n        for imgs, labels in tqdm(data_loader, desc=\"Özellik Çıkarma\"):\n            imgs = imgs.to(device)\n            features = model.extract_features(imgs)\n            all_features.append(features.cpu().numpy())\n            all_labels.append(labels.numpy())\n    \n    X = np.vstack(all_features)\n    y = np.concatenate(all_labels)\n    \n    # Veri ölçeklendirme\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    \n    # Sınıf ağırlıklarını hesapla\n    class_counts = np.bincount(y)\n    class_weights = len(y) / (len(np.unique(y)) * class_counts)\n    sample_weights = class_weights[y]\n    \n    # ML Algoritmaları ve hiperparametreler\n    ml_models = {\n        'Random Forest': {\n            'model': RandomForestClassifier(random_state=42, class_weight='balanced'),\n            'params': {\n                'n_estimators': [100, 200],  # Azaltıldı\n                'max_depth': [10, 15],\n                'min_samples_split': [2]\n            }\n        },\n        'Gradient Boosting': {\n            'model': GradientBoostingClassifier(random_state=42),\n            'params': {\n                'n_estimators': [100, 200],  # Azaltıldı\n                'learning_rate': [0.1],\n                'max_depth': [3, 5]\n            }\n        },\n        'SVM': {\n            'model': SVC(probability=True, random_state=42, class_weight='balanced'),\n            'params': {\n                'C': [1, 10],\n                'kernel': ['rbf'],\n                'gamma': ['scale']\n            }\n        },\n        'KNN': {\n            'model': KNeighborsClassifier(weights='distance'),\n            'params': {\n                'n_neighbors': [3, 5],\n                'metric': ['euclidean']\n            }\n        },\n        'Logistic Regression': {\n            'model': LogisticRegression(\n                max_iter=1000,  # Azaltıldı\n                solver='saga',\n                random_state=42,\n                class_weight='balanced',\n                n_jobs=1\n            ),\n            'params': {\n                'C': [1, 10],\n                'penalty': ['l2']\n            }\n        },\n        'Naive Bayes': {\n            'model': GaussianNB(),\n            'params': {}\n        },\n        'Decision Tree': {\n            'model': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n            'params': {\n                'max_depth': [5, 10],\n                'min_samples_split': [2],\n                'min_samples_leaf': [1]\n            }\n        },\n        'Neural Network': {\n            'model': MLPClassifier(\n                max_iter=1000,  # Azaltıldı\n                random_state=42,\n                solver='adam',\n                early_stopping=True\n            ),\n            'params': {\n                'hidden_layer_sizes': [(100,)],\n                'alpha': [0.001],\n                'learning_rate': ['adaptive']\n            }\n        }\n    }\n    \n    # Save the scaler for later use\n    try:\n        joblib.dump(scaler, 'feature_scaler.joblib')\n    except Exception as e:\n        print(f\"Scaler kaydedilemedi: {str(e)}\")\n    \n    results = {}\n    \n    # Cross-validation için StratifiedKFold - kat sayısı azaltıldı\n    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n    \n    # Her model için eğitim ve değerlendirme\n    for name, model_info in ml_models.items():\n        print(f\"\\nEğitiliyor: {name}\")\n        \n        try:\n            # Hiperparametre optimizasyonu\n            if model_info['params']:\n                grid_search = GridSearchCV(\n                    model_info['model'],\n                    model_info['params'],\n                    cv=skf,\n                    scoring='f1_weighted',\n                    n_jobs=1\n                )\n                if name in ['KNN', 'Neural Network']:\n                    grid_search.fit(X, y)\n                else:\n                    grid_search.fit(X, y, sample_weight=sample_weights)\n                best_model = grid_search.best_estimator_\n                print(f\"En iyi parametreler: {grid_search.best_params_}\")\n            else:\n                best_model = model_info['model']\n                if name in ['KNN', 'Neural Network']:\n                    best_model.fit(X, y)\n                else:\n                    best_model.fit(X, y, sample_weight=sample_weights)\n            \n            # Cross-validation sonuçları\n            cv_scores = []\n            cv_precision = []\n            cv_recall = []\n            cv_f1 = []\n            \n            for train_idx, val_idx in skf.split(X, y):\n                X_train, X_val = X[train_idx], X[val_idx]\n                y_train, y_val = y[train_idx], y[val_idx]\n                sample_weights_train = sample_weights[train_idx]\n                \n                if name in ['KNN', 'Neural Network']:\n                    best_model.fit(X_train, y_train)\n                else:\n                    best_model.fit(X_train, y_train, sample_weight=sample_weights_train)\n                y_pred = best_model.predict(X_val)\n                \n                cv_scores.append(accuracy_score(y_val, y_pred))\n                precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='weighted')\n                cv_precision.append(precision)\n                cv_recall.append(recall)\n                cv_f1.append(f1)\n            \n            # Modeli kaydet\n            try:\n                joblib.dump(best_model, f'{name.lower().replace(\" \", \"_\")}_model.joblib')\n            except Exception as e:\n                print(f\"Model kaydedilemedi: {str(e)}\")\n            \n            # Sonuçları kaydet\n            results[name] = {\n                'CV Accuracy': np.mean(cv_scores),\n                'CV Accuracy Std': np.std(cv_scores),\n                'CV Precision': np.mean(cv_precision),\n                'CV Recall': np.mean(cv_recall),\n                'CV F1': np.mean(cv_f1),\n                'Best Model': best_model\n            }\n            \n            print(f\"{name} - CV Accuracy: {results[name]['CV Accuracy']:.4f} ± {results[name]['CV Accuracy Std']:.4f}\")\n            print(f\"CV Precision: {results[name]['CV Precision']:.4f}\")\n            print(f\"CV Recall: {results[name]['CV Recall']:.4f}\")\n            print(f\"CV F1: {results[name]['CV F1']:.4f}\")\n            \n        except Exception as e:\n            print(f\"{name} modeli eğitilirken hata oluştu: {str(e)}\")\n            continue\n    \n    # Sonuçları DataFrame'e dönüştür ve kaydet\n    results_df = pd.DataFrame({\n        'Model': list(results.keys()),\n        'CV Accuracy': [results[name]['CV Accuracy'] for name in results.keys()],\n        'CV Accuracy Std': [results[name]['CV Accuracy Std'] for name in results.keys()],\n        'CV Precision': [results[name]['CV Precision'] for name in results.keys()],\n        'CV Recall': [results[name]['CV Recall'] for name in results.keys()],\n        'CV F1': [results[name]['CV F1'] for name in results.keys()]\n    })\n    \n    try:\n        results_df.to_csv('ml_results.csv', index=False)\n    except Exception as e:\n        print(f\"Sonuçlar kaydedilemedi: {str(e)}\")\n    \n    # Confusion matrix görselleştirme\n    for name in results.keys():\n        try:\n            best_model = results[name]['Best Model']\n            y_pred = best_model.predict(X)\n            cm = confusion_matrix(y, y_pred)\n            plt.figure(figsize=(8, 6))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n            plt.title(f'Confusion Matrix - {name}')\n            plt.ylabel('True Label')\n            plt.xlabel('Predicted Label')\n            plt.savefig(f'{name.lower().replace(\" \", \"_\")}_confusion_matrix.png')\n            plt.close()\n        except Exception as e:\n            print(f\"{name} için confusion matrix oluşturulamadı: {str(e)}\")\n            continue\n    \n    return results_df\n\n# ---------------------------------------\n# 9) Model Eğitimi ve ML\n# ---------------------------------------\ndef train_and_extract_features():\n    model = ResNet3DClassifier(num_classes=3, pretrained=True).to(DEVICE)\n    \n    # Sadece 1 epoch için eğitim\n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n    cls_loss_fn = CrossEntropyLoss()\n    \n    # 1 epoch eğitim\n    model.train()\n    for imgs, labels in tqdm(train_loader, desc=\"1 Epoch Eğitim\"):\n        imgs = imgs.to(DEVICE)\n        labels = labels.to(DEVICE)\n        \n        optimizer.zero_grad()\n        logits = model(imgs)\n        loss = cls_loss_fn(logits, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # Özellik çıkarma ve ML eğitimi\n    results_df = extract_features_and_train_ml(model, train_loader, DEVICE)\n    print(\"\\nML Algoritmaları Sonuçları:\")\n    print(results_df)\n    \n    return results_df\n\n# Eğitimi başlat\nif __name__ == \"__main__\":\n    results = train_and_extract_features()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:20:19.359583Z","iopub.execute_input":"2025-06-12T00:20:19.359782Z","iopub.status.idle":"2025-06-12T01:17:00.272932Z","shell.execute_reply.started":"2025-06-12T00:20:19.359765Z","shell.execute_reply":"2025-06-12T01:17:00.263166Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nTotal sample sayısı: 2182\nSınıf dağılımı: {'CN': 748, 'MCI': 981, 'AD': 453}\nTrain / Test sayıları: 1745/437\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/r3d_18-b3b3357e.pth\" to /root/.cache/torch/hub/checkpoints/r3d_18-b3b3357e.pth\n100%|██████████| 127M/127M [00:00<00:00, 171MB/s]  \n1 Epoch Eğitim: 100%|██████████| 873/873 [11:28<00:00,  1.27it/s]\nÖzellik Çıkarma: 100%|██████████| 873/873 [09:37<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEğitiliyor: Random Forest\nEn iyi parametreler: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}\nRandom Forest - CV Accuracy: 0.6464 ± 0.0264\nCV Precision: 0.6509\nCV Recall: 0.6464\nCV F1: 0.6418\n\nEğitiliyor: Gradient Boosting\nEn iyi parametreler: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\nGradient Boosting - CV Accuracy: 0.6877 ± 0.0212\nCV Precision: 0.6887\nCV Recall: 0.6877\nCV F1: 0.6859\n\nEğitiliyor: SVM\nEn iyi parametreler: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\nSVM - CV Accuracy: 0.6310 ± 0.0350\nCV Precision: 0.6771\nCV Recall: 0.6310\nCV F1: 0.6294\n\nEğitiliyor: KNN\nEn iyi parametreler: {'metric': 'euclidean', 'n_neighbors': 3}\nKNN - CV Accuracy: 0.6504 ± 0.0099\nCV Precision: 0.6519\nCV Recall: 0.6504\nCV F1: 0.6475\n\nEğitiliyor: Logistic Regression\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"En iyi parametreler: {'C': 10, 'penalty': 'l2'}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Logistic Regression - CV Accuracy: 0.6195 ± 0.0080\nCV Precision: 0.6494\nCV Recall: 0.6195\nCV F1: 0.6201\n\nEğitiliyor: Naive Bayes\nNaive Bayes - CV Accuracy: 0.3719 ± 0.0252\nCV Precision: 0.4634\nCV Recall: 0.3719\nCV F1: 0.3358\n\nEğitiliyor: Decision Tree\nEn iyi parametreler: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\nDecision Tree - CV Accuracy: 0.5203 ± 0.0067\nCV Precision: 0.5400\nCV Recall: 0.5203\nCV F1: 0.5213\n\nEğitiliyor: Neural Network\nEn iyi parametreler: {'alpha': 0.001, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive'}\nNeural Network - CV Accuracy: 0.6533 ± 0.0478\nCV Precision: 0.6540\nCV Recall: 0.6533\nCV F1: 0.6496\n\nML Algoritmaları Sonuçları:\n                 Model  CV Accuracy  CV Accuracy Std  CV Precision  CV Recall  \\\n0        Random Forest     0.646425         0.026436      0.650893   0.646425   \n1    Gradient Boosting     0.687685         0.021154      0.688743   0.687685   \n2                  SVM     0.630969         0.035005      0.677064   0.630969   \n3                  KNN     0.650438         0.009878      0.651909   0.650438   \n4  Logistic Regression     0.619487         0.007952      0.649429   0.619487   \n5          Naive Bayes     0.371933         0.025150      0.463357   0.371933   \n6        Decision Tree     0.520340         0.006732      0.540013   0.520340   \n7       Neural Network     0.653317         0.047831      0.654029   0.653317   \n\n      CV F1  \n0  0.641840  \n1  0.685886  \n2  0.629397  \n3  0.647506  \n4  0.620069  \n5  0.335815  \n6  0.521290  \n7  0.649568  \n","output_type":"stream"}],"execution_count":1}]}