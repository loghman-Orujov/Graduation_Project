{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12036716,"sourceType":"datasetVersion","datasetId":7573927}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport nibabel as nib\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import CrossEntropyLoss\nfrom tqdm import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy import ndimage\nfrom skimage.filters import threshold_otsu\nfrom torch.cuda.amp import autocast, GradScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport torch.nn.functional as F\n\n# ---------------------------------------\n# CUDA Ayarları\n# ---------------------------------------\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.backends.cudnn.benchmark = True\n\n# Multi-GPU ayarları\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    # Her GPU için batch size'ı ayarla\n    BATCH_SIZE_PER_GPU = 12  # T4 için optimize edilmiş batch size\n    BATCH_SIZE = BATCH_SIZE_PER_GPU * torch.cuda.device_count()\nelse:\n    BATCH_SIZE = 12\n    print(\"Using single GPU\")\n\n# ---------------------------------------\n# Eğitim Parametreleri\n# ---------------------------------------\nnum_epochs = 20  # Epoch sayısı 20'ye düşürüldü\npatience = 5  # Early stopping için patience azaltıldı\nmin_delta = 0.0005  # Early stopping için minimum değişim\n\n# Başlangıç hiperparametreleri\ninitial_hyperparams = {\n    'lr': 1e-3,\n    'weight_decay': 1e-4,\n    'dropout': 0.3\n}\n\n# Fold sonuçlarını saklamak için\nfold_results = []\nfold1_metrics = None\n\n# ---------------------------------------\n# 1) Veri Yolu ve Sınıflar\n# ---------------------------------------\nDATA_DIR = '/kaggle/input/adniunpreprocessed'\nclasses = {'CN': 0, 'MCI': 1, 'AD': 2}\n\n# Dosyaları topla ve her sınıftan 300 örneğe indir\nall_files = glob.glob(os.path.join(DATA_DIR, '**', '*.nii*'), recursive=True)\nclass_paths = {c: [] for c in classes}\nfor fp in all_files:\n    parent = os.path.basename(os.path.dirname(fp))\n    if parent in classes and os.path.getsize(fp) > 0:\n        try:\n            nib.load(fp)\n            class_paths[parent].append(fp)\n        except:\n            pass\n\nlimited_paths, limited_labels = [], []\nfor cls, paths in class_paths.items():\n    random.shuffle(paths)\n    selected = paths[:300]\n    limited_paths.extend(selected)\n    limited_labels.extend([classes[cls]] * len(selected))\n\nlimited_paths = np.array(limited_paths)\nlimited_labels = np.array(limited_labels)\n\n# ---------------------------------------\n# 2) Dataset ve Basit Augmentasyon\n# ---------------------------------------\nPATCH_SIZE = 112\nclass ADNI_Dataset(Dataset):\n    def __init__(self, paths, labels, augment=False):\n        self.paths = paths\n        self.labels = labels\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img = nib.load(self.paths[idx]).get_fdata().astype(np.float32)\n        \n        # Daha güçlü normalizasyon\n        p1, p99 = np.percentile(img, (1, 99))\n        img = np.clip(img, p1, p99)\n        img = (img - p1) / (p99 - p1 + 1e-6)\n        \n        # Beyin maskeleme ve temizleme\n        thresh = threshold_otsu(img)\n        mask = img > thresh\n        mask = ndimage.binary_closing(mask, structure=np.ones((5,5,5)))  # Daha büyük kernel\n        mask = ndimage.binary_fill_holes(mask)\n        mask = ndimage.binary_dilation(mask, structure=np.ones((5,5,5)))  # Daha büyük kernel\n        labeled, nf = ndimage.label(mask)\n        if nf > 1:\n            counts = np.bincount(labeled.ravel()); counts[0] = 0\n            mask = (labeled == counts.argmax())\n        \n        # Maske uygula\n        img = img * mask\n        \n        # Patch crop\n        coords = np.array(np.where(mask))\n        mins, maxs = coords.min(axis=1), coords.max(axis=1)\n        center = ((mins + maxs) // 2).astype(int)\n        \n        half = PATCH_SIZE // 2\n        starts = center - half\n        ends = starts + PATCH_SIZE\n        \n        # Sınırları kontrol et\n        for i, dim in enumerate(img.shape):\n            if starts[i] < 0: starts[i] = 0; ends[i] = PATCH_SIZE\n            if ends[i] > dim: ends[i] = dim; starts[i] = dim - PATCH_SIZE\n        \n        patch = img[starts[0]:ends[0], starts[1]:ends[1], starts[2]:ends[2]]\n        \n        # Padding\n        if patch.shape != (PATCH_SIZE,)*3:\n            pad = np.zeros((PATCH_SIZE,)*3, np.float32)\n            pd, ph, pw = patch.shape\n            sd, sh, sw = [(PATCH_SIZE - s)//2 for s in patch.shape]\n            pad[sd:sd+pd, sh:sh+ph, sw:sw+pw] = patch\n            patch = pad\n\n        # Geliştirilmiş normalizasyon\n        patch = (patch - patch.mean()) / (patch.std() + 1e-6)\n        \n        # Geliştirilmiş augmentasyon\n        if self.augment:\n            # Random flip (tüm eksenlerde)\n            for axis in [0, 1, 2]:\n                if random.random() < 0.5:\n                    patch = np.flip(patch, axis=axis).copy()\n            \n            # Random rotation (daha geniş açı aralığı)\n            if random.random() < 0.5:\n                angle = random.uniform(-15, 15)\n                patch = ndimage.rotate(patch, angle, axes=(0,1), reshape=False)\n            \n            # Random brightness (daha geniş aralık)\n            if random.random() < 0.5:\n                patch = patch * random.uniform(0.7, 1.3)\n            \n            # Random contrast (daha güçlü)\n            if random.random() < 0.5:\n                patch = (patch - patch.mean()) * random.uniform(0.7, 1.3) + patch.mean()\n            \n            # Gaussian noise (daha kontrollü)\n            if random.random() < 0.5:\n                noise_level = random.uniform(0.01, 0.03)\n                patch += np.random.normal(0, noise_level, size=patch.shape).astype(np.float32)\n            \n            # Random zoom (yeni)\n            if random.random() < 0.3:\n                zoom_factor = random.uniform(0.9, 1.1)\n                patch = ndimage.zoom(patch, zoom_factor, order=1)\n                if patch.shape != (PATCH_SIZE,)*3:\n                    # Yeniden boyutlandır\n                    patch = ndimage.zoom(patch, PATCH_SIZE/patch.shape[0], order=1)\n\n        tensor = torch.from_numpy(patch).unsqueeze(0)\n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return tensor, label\n\n# ---------------------------------------\n# 3) Model Tanımı (Inception3D + SE + Attention)\n# ---------------------------------------\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super().__init__()\n        self.fc1 = nn.Linear(channels, channels//reduction, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Linear(channels//reduction, channels, bias=False)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        b,c,d,h,w = x.size()\n        y = x.view(b,c,-1).mean(dim=2)\n        y = self.relu(self.fc1(y))\n        y = self.sigmoid(self.fc2(y)).view(b,c,1,1,1)\n        return x * y\n\nclass AttentionBlock(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.conv1 = nn.Conv3d(in_channels, in_channels//8, 1)\n        self.conv2 = nn.Conv3d(in_channels//8, in_channels, 1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        attention = F.avg_pool3d(x, x.size()[2:])\n        attention = F.relu(self.conv1(attention))\n        attention = self.sigmoid(self.conv2(attention))\n        return x * attention\n\nclass Inception3D_SE_Attention(nn.Module):\n    def __init__(self, in_ch, c1, c3r, c3, c5r, c5, pp):\n        super().__init__()\n        self.b1 = nn.Sequential(nn.Conv3d(in_ch,c1,1,bias=False), nn.BatchNorm3d(c1), nn.ReLU(True))\n        self.b3 = nn.Sequential(nn.Conv3d(in_ch,c3r,1,bias=False), nn.BatchNorm3d(c3r), nn.ReLU(True),\n                              nn.Conv3d(c3r,c3,3,padding=1,bias=False), nn.BatchNorm3d(c3), nn.ReLU(True))\n        self.b5 = nn.Sequential(nn.Conv3d(in_ch,c5r,1,bias=False), nn.BatchNorm3d(c5r), nn.ReLU(True),\n                              nn.Conv3d(c5r,c5,5,padding=2,bias=False), nn.BatchNorm3d(c5), nn.ReLU(True))\n        self.bp = nn.Sequential(nn.MaxPool3d(3,1,1), nn.Conv3d(in_ch,pp,1,bias=False), nn.BatchNorm3d(pp), nn.ReLU(True))\n        out_ch = c1+c3+c5+pp\n        self.se = SEBlock(out_ch)\n        self.attention = AttentionBlock(out_ch)\n        \n    def forward(self, x):\n        out = torch.cat([self.b1(x), self.b3(x), self.b5(x), self.bp(x)], dim=1)\n        out = self.se(out)\n        out = self.attention(out)\n        return out\n\nclass Inception3DNet_SE_Attention(nn.Module):\n    def __init__(self, num_classes=3, dropout_rate=0.3):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv3d(1, 64, 7, 2, 3, bias=False),\n            nn.BatchNorm3d(64),\n            nn.ReLU(True),\n            nn.MaxPool3d(3, 2, 1)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv3d(64, 64, 1, bias=False),\n            nn.BatchNorm3d(64),\n            nn.ReLU(True),\n            nn.Conv3d(64, 192, 3, 1, 1, bias=False),\n            nn.BatchNorm3d(192),\n            nn.ReLU(True),\n            nn.MaxPool3d(3, 2, 1)\n        )\n        self.i3a = Inception3D_SE_Attention(192, 64, 96, 128, 16, 32, 32)\n        self.i3b = Inception3D_SE_Attention(256, 128, 128, 192, 32, 96, 64)\n        self.mp3 = nn.MaxPool3d(3, 2, 1)\n        self.i3c = Inception3D_SE_Attention(480, 192, 96, 208, 16, 48, 64)\n        self.i3d = Inception3D_SE_Attention(512, 160, 112, 224, 24, 64, 64)\n        self.i3e = Inception3D_SE_Attention(512, 128, 128, 256, 24, 64, 64)\n        self.mp4 = nn.MaxPool3d(3, 2, 1)\n        self.avgp = nn.AdaptiveAvgPool3d((1, 1, 1))\n        self.drop = nn.Dropout(dropout_rate)\n        self.fc = nn.Linear(512, num_classes)\n        \n        # Weight initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv3d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm3d, nn.GroupNorm)):\n                if hasattr(m, 'weight') and m.weight is not None:\n                    nn.init.constant_(m.weight, 1)\n                if hasattr(m, 'bias') and m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n                    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.i3a(x)\n        x = self.i3b(x)\n        x = self.mp3(x)\n        x = self.i3c(x)\n        x = self.i3d(x)\n        x = self.i3e(x)\n        x = self.mp4(x)\n        x = self.avgp(x)\n        x = self.drop(x.flatten(1))\n        return self.fc(x)\n\n# ---------------------------------------\n# 4) 2-Fold Cross-Validation -> Her Fold 20 Epoch\n# ---------------------------------------\nskf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n\nfor fold, (tr_idx, va_idx) in enumerate(skf.split(limited_paths, limited_labels), 1):\n    print(f\"\\n=== Fold {fold}/2 ===\")\n    \n    # Fold1 sonuçlarına göre hiperparametreleri ayarla\n    if fold == 1:\n        current_hyperparams = initial_hyperparams\n    else:\n        # Fold1 sonuçlarına göre hiperparametreleri dinamik olarak ayarla\n        if fold1_metrics is not None:\n            # Validation accuracy'ye göre learning rate ayarla\n            if fold1_metrics['val_acc'] < 0.7:\n                current_hyperparams['lr'] *= 1.5  # Düşük accuracy için learning rate'i artır\n            elif fold1_metrics['val_acc'] > 0.85:\n                current_hyperparams['lr'] *= 0.8  # Yüksek accuracy için learning rate'i azalt\n            \n            # Validation loss'a göre dropout ayarla\n            if fold1_metrics['val_loss'] > 1.0:\n                current_hyperparams['dropout'] = min(0.5, current_hyperparams['dropout'] + 0.05)  # Overfitting varsa dropout'u artır\n            elif fold1_metrics['val_loss'] < 0.5:\n                current_hyperparams['dropout'] = max(0.2, current_hyperparams['dropout'] - 0.05)  # Underfitting varsa dropout'u azalt\n            \n            # Validation accuracy ve loss'a göre weight decay ayarla\n            if fold1_metrics['val_acc'] < 0.7 and fold1_metrics['val_loss'] > 1.0:\n                current_hyperparams['weight_decay'] *= 1.5  # Düşük performans için regularization'ı artır\n            elif fold1_metrics['val_acc'] > 0.85 and fold1_metrics['val_loss'] < 0.5:\n                current_hyperparams['weight_decay'] *= 0.8  # Yüksek performans için regularization'ı azalt\n        else:\n            current_hyperparams = initial_hyperparams\n    \n    print(f\"\\nFold {fold} Hyperparameters:\")\n    print(f\"Learning Rate: {current_hyperparams['lr']}\")\n    print(f\"Weight Decay: {current_hyperparams['weight_decay']}\")\n    print(f\"Dropout: {current_hyperparams['dropout']}\")\n    \n    # Data split\n    tr_p, tr_l = limited_paths[tr_idx], limited_labels[tr_idx]\n    va_p, va_l = limited_paths[va_idx], limited_labels[va_idx]\n    \n    # Sınıf dağılımını kontrol et ve class weights hesapla\n    class_counts = Counter(tr_l)\n    total_samples = len(tr_l)\n    class_weights = {cls: total_samples / (len(class_counts) * count) for cls, count in class_counts.items()}\n    class_weights = torch.tensor([class_weights[i] for i in range(len(class_counts))]).to(DEVICE)\n    \n    print(\"\\nTrain set class distribution:\")\n    print(Counter(tr_l))\n    print(\"\\nValidation set class distribution:\")\n    print(Counter(va_l))\n    print(\"\\nClass weights:\", class_weights)\n\n    # Dataset ve DataLoader\n    train_ds = ADNI_Dataset(tr_p, tr_l, augment=True)\n    val_ds   = ADNI_Dataset(va_p, va_l, augment=False)\n    \n    train_loader = DataLoader(\n        train_ds, \n        batch_size=BATCH_SIZE, \n        shuffle=True, \n        num_workers=4, \n        pin_memory=True, \n        prefetch_factor=2,\n        persistent_workers=True\n    )\n    val_loader = DataLoader(\n        val_ds,   \n        batch_size=BATCH_SIZE, \n        shuffle=False, \n        num_workers=4, \n        pin_memory=True, \n        prefetch_factor=2,\n        persistent_workers=True\n    )\n\n    # Model, loss, optimizer\n    model = Inception3DNet_SE_Attention(3, dropout_rate=current_hyperparams['dropout']).to(DEVICE)\n    if torch.cuda.device_count() > 1:\n        model = nn.DataParallel(model)\n    \n    # Weighted Cross Entropy Loss\n    criterion = CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=current_hyperparams['lr'], weight_decay=current_hyperparams['weight_decay'])\n    \n    # Cosine Annealing with Warm Restarts\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer,\n        T_0=5,  # İlk restart periyodu azaltıldı\n        T_mult=2,  # Her restart'ta periyodu 2 katına çıkar\n        eta_min=current_hyperparams['lr'] * 0.01  # Minimum learning rate\n    )\n    \n    scaler = GradScaler()\n\n    # Eğitim metrikleri\n    train_losses, val_losses = [], []\n    train_accs, val_accs = [], []\n    best_val_acc = 0.0\n    best_epoch = 0\n    no_improve = 0\n\n    # Eğitim döngüsü\n    for epoch in range(1, num_epochs + 1):\n        # Train\n        model.train()\n        run_loss = corr = tot = 0\n        for imgs, labels in tqdm(train_loader, desc=f\"Fold {fold} Train E{epoch}\"):\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            optimizer.zero_grad()\n            \n            with autocast():\n                logits = model(imgs)\n                loss = criterion(logits, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            run_loss += loss.item()\n            preds = logits.argmax(1)\n            corr += (preds==labels).sum().item()\n            tot += labels.size(0)\n        \n        train_loss = run_loss/len(train_loader)\n        train_acc = corr/tot\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n        print(f\"Epoch {epoch}/{num_epochs}: Train Loss {train_loss:.4f}, Train Acc {train_acc:.4f}\")\n\n        # Validation\n        model.eval()\n        val_loss = corr = tot = 0\n        with torch.no_grad():\n            for imgs, labels in tqdm(val_loader, desc=f\"Fold {fold} Val\"):\n                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n                with autocast():\n                    logits = model(imgs)\n                    loss = criterion(logits, labels)\n                val_loss += loss.item()\n                preds = logits.argmax(1)\n                corr += (preds==labels).sum().item()\n                tot += labels.size(0)\n        \n        val_loss = val_loss/len(val_loader)\n        val_acc = corr/tot\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        print(f\"Val Loss {val_loss:.4f}, Val Acc {val_acc:.4f}\")\n\n        # Learning rate scheduler update\n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f\"Current learning rate: {current_lr:.6f}\")\n\n        # Early stopping kontrolü\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            best_epoch = epoch\n            no_improve = 0\n            if isinstance(model, nn.DataParallel):\n                torch.save(model.module.state_dict(), f'best_model_fold_{fold}.pth')\n            else:\n                torch.save(model.state_dict(), f'best_model_fold_{fold}.pth')\n            print(f\"Yeni en iyi model kaydedildi (Val Acc: {val_acc:.4f})\")\n        else:\n            no_improve += 1\n            if no_improve >= patience:\n                print(f\"\\nEarly stopping triggered! No improvement for {patience} epochs.\")\n                print(f\"Best validation accuracy: {best_val_acc:.4f} at epoch {best_epoch}\")\n                break\n\n    # Fold sonuçlarını kaydet\n    fold_metrics = {\n        'fold': fold,\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'train_accs': train_accs,\n        'val_accs': val_accs,\n        'best_val_acc': best_val_acc,\n        'best_epoch': best_epoch,\n        'hyperparams': current_hyperparams\n    }\n    fold_results.append(fold_metrics)\n    \n    # Fold1 sonuçlarını sakla\n    if fold == 1:\n        fold1_metrics = {\n            'val_acc': best_val_acc,\n            'val_loss': val_losses[best_epoch-1]\n        }\n\n    # Fold sonuçlarını görselleştir\n    plt.figure(figsize=(15, 5))\n    \n    # Loss plot\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train')\n    plt.plot(val_losses, label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title(f'Training and Validation Loss - Fold {fold}')\n    plt.legend()\n    \n    # Accuracy plot\n    plt.subplot(1, 2, 2)\n    plt.plot(train_accs, label='Train')\n    plt.plot(val_accs, label='Val')\n    plt.axvline(x=best_epoch, color='r', linestyle='--', label=f'Best Epoch ({best_epoch})')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title(f'Training and Validation Accuracy - Fold {fold}')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# Final sonuçları\nfold_accs = [result['best_val_acc'] for result in fold_results]\nprint(f\"\\n2-Fold Sonuçları:\")\nfor i, result in enumerate(fold_results, 1):\n    hp = result['hyperparams']\n    print(f\"Fold {i}: {result['best_val_acc']:.4f} (lr={hp['lr']}, wd={hp['weight_decay']}, dropout={hp['dropout']})\")\nprint(f\"Ortalama Acc: {np.mean(fold_accs):.4f} ± {np.std(fold_accs):.4f}\")\n\n# Final test - Test seti için ayrı bir değerlendirme\nprint(\"\\nFinal Test Results on Test Set:\")\n\n# En iyi fold'u bul\nbest_fold = np.argmax(fold_accs) + 1\nprint(f\"Using best model from Fold {best_fold}\")\n\n# Test seti için son 20% veriyi kullan\ntest_size = int(len(limited_paths) * 0.2)\ntest_indices = np.random.choice(len(limited_paths), test_size, replace=False)\ntest_paths = limited_paths[test_indices]\ntest_labels = limited_labels[test_indices]\n\n# Test dataset oluştur\ntest_ds = ADNI_Dataset(test_paths, test_labels, augment=False)\n\n# Test seti için DataLoader\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True,\n    prefetch_factor=2,\n    persistent_workers=True\n)\n\n# En iyi modeli yükle\ntest_model = Inception3DNet_SE_Attention(3, dropout_rate=fold_results[best_fold-1]['hyperparams']['dropout']).to(DEVICE)\nif torch.cuda.device_count() > 1:\n    test_model = nn.DataParallel(test_model)\ntest_model.load_state_dict(torch.load(f'best_model_fold_{best_fold}.pth'))\ntest_model.eval()\n\n# Test seti değerlendirmesi\nall_test_targets = []\nall_test_preds = []\nall_test_probs = []\nall_test_losses = []\n\nwith torch.no_grad():\n    for imgs, labels in tqdm(test_loader, desc=\"Testing on Test Set\"):\n        imgs = imgs.to(DEVICE)\n        labels = labels.to(DEVICE)\n        \n        with autocast():\n            logits = test_model(imgs)\n            probs = F.softmax(logits, dim=1)\n            loss = criterion(logits, labels)\n        \n        preds = logits.argmax(1)\n        all_test_targets.extend(labels.cpu().numpy())\n        all_test_preds.extend(preds.cpu().numpy())\n        all_test_probs.extend(probs.cpu().numpy())\n        all_test_losses.append(loss.item())\n\n# Test seti metrikleri\ntest_loss = np.mean(all_test_losses)\ntest_acc = np.mean(np.array(all_test_preds) == np.array(all_test_targets))\nprint(f\"\\nTest Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n\n# Per-class metrics\nprint(\"\\nPer-class Metrics:\")\nclass_names = [\"CN\", \"MCI\", \"AD\"]\nprint(classification_report(all_test_targets, all_test_preds, target_names=class_names))\n\n# ROC ve AUC hesapla\nauc_scores = []\nplt.figure(figsize=(10, 8))\nfor i, label in enumerate(class_names):\n    auc = roc_auc_score(np.array(all_test_targets) == i, np.array(all_test_probs)[:, i])\n    auc_scores.append(auc)\n    fpr, tpr, _ = roc_curve(np.array(all_test_targets) == i, np.array(all_test_probs)[:, i])\n    plt.plot(fpr, tpr, label=f'{label} (AUC = {auc:.3f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curves - Test Set')\nplt.legend()\nplt.savefig('roc_curves.png')\nplt.close()\n\n# Confusion Matrix\ncm = confusion_matrix(all_test_targets, all_test_preds)\nplt.figure(figsize=(10, 8))\nsns.heatmap(\n    cm,\n    annot=True,\n    fmt='d',\n    xticklabels=class_names,\n    yticklabels=class_names,\n    cmap='Blues'\n)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Test Set Confusion Matrix\")\nplt.savefig('confusion_matrix.png')\nplt.close()\n\n# Per-class accuracy\nclass_accuracies = cm.diagonal() / cm.sum(axis=1)\nplt.figure(figsize=(10, 6))\nplt.bar(class_names, class_accuracies)\nplt.title('Per-class Accuracy')\nplt.ylabel('Accuracy')\nplt.ylim(0, 1)\nfor i, acc in enumerate(class_accuracies):\n    plt.text(i, acc + 0.02, f'{acc:.3f}', ha='center')\nplt.savefig('per_class_accuracy.png')\nplt.close()\n\n# Learning curves for best fold\nbest_fold_metrics = fold_results[best_fold-1]\nplt.figure(figsize=(15, 5))\n\n# Loss plot\nplt.subplot(1, 2, 1)\nplt.plot(best_fold_metrics['train_losses'], label='Train')\nplt.plot(best_fold_metrics['val_losses'], label='Val')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title(f'Learning Curves - Best Fold ({best_fold})')\nplt.legend()\n\n# Accuracy plot\nplt.subplot(1, 2, 2)\nplt.plot(best_fold_metrics['train_accs'], label='Train')\nplt.plot(best_fold_metrics['val_accs'], label='Val')\nplt.axvline(x=best_fold_metrics['best_epoch'], color='r', linestyle='--', \n            label=f'Best Epoch ({best_fold_metrics[\"best_epoch\"]})')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title(f'Accuracy Curves - Best Fold ({best_fold})')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig('best_fold_curves.png')\nplt.close()\n\n# Final rapor\nprint(\"\\nFinal Test Results Summary:\")\nprint(f\"Best Fold: {best_fold}\")\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nprint(\"\\nPer-class AUC Scores:\")\nfor i, (label, auc) in enumerate(zip(class_names, auc_scores)):\n    print(f\"{label}: {auc:.4f}\")\nprint(\"\\nPer-class Accuracies:\")\nfor i, (label, acc) in enumerate(zip(class_names, class_accuracies)):\n    print(f\"{label}: {acc:.4f}\")\n\n# Model ve hiperparametre bilgilerini kaydet\nwith open('test_results.txt', 'w') as f:\n    f.write(\"Test Results Summary\\n\")\n    f.write(\"===================\\n\\n\")\n    f.write(f\"Best Fold: {best_fold}\\n\")\n    f.write(f\"Test Loss: {test_loss:.4f}\\n\")\n    f.write(f\"Test Accuracy: {test_acc:.4f}\\n\\n\")\n    f.write(\"Hyperparameters:\\n\")\n    hp = fold_results[best_fold-1]['hyperparams']\n    f.write(f\"Learning Rate: {hp['lr']}\\n\")\n    f.write(f\"Weight Decay: {hp['weight_decay']}\\n\")\n    f.write(f\"Dropout: {hp['dropout']}\\n\\n\")\n    f.write(\"Per-class Metrics:\\n\")\n    f.write(classification_report(all_test_targets, all_test_preds, target_names=class_names))\n    f.write(\"\\nPer-class AUC Scores:\\n\")\n    for i, (label, auc) in enumerate(zip(class_names, auc_scores)):\n        f.write(f\"{label}: {auc:.4f}\\n\")\n    f.write(\"\\nPer-class Accuracies:\\n\")\n    for i, (label, acc) in enumerate(zip(class_names, class_accuracies)):\n        f.write(f\"{label}: {acc:.4f}\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}