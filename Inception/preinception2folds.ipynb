{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ad7e0a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-11T07:34:10.197168Z",
     "iopub.status.busy": "2025-06-11T07:34:10.196918Z",
     "iopub.status.idle": "2025-06-11T19:24:26.226173Z",
     "shell.execute_reply": "2025-06-11T19:24:26.225281Z"
    },
    "papermill": {
     "duration": 42616.033755,
     "end_time": "2025-06-11T19:24:26.227381",
     "exception": false,
     "start_time": "2025-06-11T07:34:10.193626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Starting training...\n",
      "\n",
      "===== Fold 1/2 =====\n",
      "Hyperparameters: {'lr': 0.0001, 'batch_size': 4, 'weight_decay': 0.0001, 'dropout': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 1.1160, Train Acc: 0.3358, Val Loss: 1.1011, Val Acc: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 1.0878, Train Acc: 0.4074, Val Loss: 1.0629, Val Acc: 0.4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 1.0688, Train Acc: 0.3778, Val Loss: 1.0347, Val Acc: 0.5580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 1.0211, Train Acc: 0.4617, Val Loss: 1.0099, Val Acc: 0.4889\n",
      "Epoch 5/20 - Train Loss: 0.9754, Train Acc: 0.5012, Val Loss: 0.9592, Val Acc: 0.5926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.8704, Train Acc: 0.6049, Val Loss: 0.9683, Val Acc: 0.5062\n",
      "Epoch 7/20 - Train Loss: 0.7393, Train Acc: 0.6716, Val Loss: 0.8714, Val Acc: 0.5975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.6692, Train Acc: 0.7012, Val Loss: 0.8168, Val Acc: 0.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.5592, Train Acc: 0.7259, Val Loss: 0.8289, Val Acc: 0.6000\n",
      "Epoch 10/20 - Train Loss: 0.4711, Train Acc: 0.7728, Val Loss: 0.8311, Val Acc: 0.6173\n",
      "Epoch 11/20 - Train Loss: 0.4171, Train Acc: 0.7802, Val Loss: 0.7236, Val Acc: 0.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train Loss: 0.3830, Train Acc: 0.7901, Val Loss: 0.6965, Val Acc: 0.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train Loss: 0.3205, Train Acc: 0.8173, Val Loss: 0.6693, Val Acc: 0.6988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train Loss: 0.3614, Train Acc: 0.7901, Val Loss: 0.6550, Val Acc: 0.7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train Loss: 0.3636, Train Acc: 0.7630, Val Loss: 0.6581, Val Acc: 0.7185\n",
      "Epoch 16/20 - Train Loss: 0.3153, Train Acc: 0.8272, Val Loss: 0.6546, Val Acc: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Train Loss: 0.3266, Train Acc: 0.7951, Val Loss: 0.6534, Val Acc: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train Loss: 0.3448, Train Acc: 0.7901, Val Loss: 0.6545, Val Acc: 0.7210\n",
      "Epoch 19/20 - Train Loss: 0.2767, Train Acc: 0.8395, Val Loss: 0.6552, Val Acc: 0.7358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train Loss: 0.2853, Train Acc: 0.8222, Val Loss: 0.6570, Val Acc: 0.7210\n",
      "\n",
      "Hyperparameter optimization:\n",
      "Previous fold val_acc: 0.7358\n",
      "Previous params: {'lr': 0.0001, 'batch_size': 4, 'weight_decay': 0.0001, 'dropout': 0.3}\n",
      "New params: {'lr': 0.0001, 'batch_size': 2, 'weight_decay': 0.0001, 'dropout': 0.3}\n",
      "\n",
      "===== Fold 2/2 =====\n",
      "Hyperparameters: {'lr': 0.0001, 'batch_size': 2, 'weight_decay': 0.0001, 'dropout': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 1.1482, Train Acc: 0.3235, Val Loss: 1.1128, Val Acc: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 1.0826, Train Acc: 0.3852, Val Loss: 1.0708, Val Acc: 0.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.9985, Train Acc: 0.5012, Val Loss: 1.0139, Val Acc: 0.5160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.9285, Train Acc: 0.5333, Val Loss: 1.0020, Val Acc: 0.4840\n",
      "Epoch 5/20 - Train Loss: 0.8665, Train Acc: 0.5556, Val Loss: 0.9199, Val Acc: 0.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.7733, Train Acc: 0.6000, Val Loss: 0.9171, Val Acc: 0.5753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.6934, Train Acc: 0.6716, Val Loss: 0.8882, Val Acc: 0.5901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.6095, Train Acc: 0.7012, Val Loss: 0.9306, Val Acc: 0.5827\n",
      "Epoch 9/20 - Train Loss: 0.4592, Train Acc: 0.7901, Val Loss: 0.8375, Val Acc: 0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.3820, Train Acc: 0.8123, Val Loss: 0.8335, Val Acc: 0.6370\n",
      "Epoch 11/20 - Train Loss: 0.4868, Train Acc: 0.7506, Val Loss: 0.9230, Val Acc: 0.5951\n",
      "Epoch 12/20 - Train Loss: 0.4674, Train Acc: 0.7432, Val Loss: 0.8890, Val Acc: 0.6296\n",
      "Epoch 13/20 - Train Loss: 0.4081, Train Acc: 0.7802, Val Loss: 0.9636, Val Acc: 0.5728\n",
      "Epoch 14/20 - Train Loss: 0.3891, Train Acc: 0.7704, Val Loss: 1.0583, Val Acc: 0.5877\n",
      "Epoch 15/20 - Train Loss: 0.3449, Train Acc: 0.7975, Val Loss: 0.7685, Val Acc: 0.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Train Loss: 0.3509, Train Acc: 0.7753, Val Loss: 0.7678, Val Acc: 0.6914\n",
      "Epoch 17/20 - Train Loss: 0.3527, Train Acc: 0.7827, Val Loss: 0.7669, Val Acc: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:1597: UserWarning: dropout3d: Received a 2-D input to dropout3d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout3d exists to provide channel-wise dropout on inputs with 3 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 4D or 5D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train Loss: 0.3094, Train Acc: 0.8000, Val Loss: 0.7757, Val Acc: 0.6938\n",
      "Epoch 19/20 - Train Loss: 0.2976, Train Acc: 0.8272, Val Loss: 0.7779, Val Acc: 0.6914\n",
      "Epoch 20/20 - Train Loss: 0.2865, Train Acc: 0.8222, Val Loss: 0.7775, Val Acc: 0.6963\n",
      "\n",
      "===== Final Results =====\n",
      "\n",
      "Fold 1:\n",
      "Best Validation Accuracy: 0.7358\n",
      "Hyperparameters: {'lr': 0.0001, 'batch_size': 4, 'weight_decay': 0.0001, 'dropout': 0.3}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.82      0.72      0.76       135\n",
      "         MCI       0.66      0.64      0.65       135\n",
      "          AD       0.74      0.84      0.79       135\n",
      "\n",
      "    accuracy                           0.74       405\n",
      "   macro avg       0.74      0.74      0.73       405\n",
      "weighted avg       0.74      0.74      0.73       405\n",
      "\n",
      "\n",
      "Fold 2:\n",
      "Best Validation Accuracy: 0.7037\n",
      "Hyperparameters: {'lr': 0.0001, 'batch_size': 2, 'weight_decay': 0.0001, 'dropout': 0.3}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.68      0.71      0.70       135\n",
      "         MCI       0.63      0.61      0.62       135\n",
      "          AD       0.80      0.79      0.79       135\n",
      "\n",
      "    accuracy                           0.70       405\n",
      "   macro avg       0.70      0.70      0.70       405\n",
      "weighted avg       0.70      0.70      0.70       405\n",
      "\n",
      "\n",
      "Results saved in directory: results_20250611_073518\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy import ndimage\n",
    "from torch.amp import autocast, GradScaler\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------------------------------\n",
    "# CUDA ve CUDNN Ayarları\n",
    "# ---------------------------------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Veri Yükleme ve Ön İşleme\n",
    "# ---------------------------------------\n",
    "DATA_DIR = '/kaggle/input/adniprocessed'\n",
    "classes = {\n",
    "    'CN_Combined': 0,\n",
    "    'MCI_Combined': 1,\n",
    "    'AD_Combined': 2\n",
    "}\n",
    "\n",
    "# Veri yükleme ve filtreleme\n",
    "all_mgz = glob.glob(os.path.join(DATA_DIR, '**', '*.mgz'), recursive=True)\n",
    "orig_files = [p for p in all_mgz if os.path.basename(p).lower() == 'orig.mgz']\n",
    "\n",
    "valid_paths, valid_labels = [], []\n",
    "for orig_path in orig_files:\n",
    "    group_name = None\n",
    "    cur_dir = os.path.dirname(orig_path)\n",
    "    while True:\n",
    "        cur_dir = os.path.dirname(cur_dir)\n",
    "        if os.path.basename(cur_dir) in classes:\n",
    "            group_name = os.path.basename(cur_dir)\n",
    "            break\n",
    "        if os.path.abspath(cur_dir) == os.path.abspath(DATA_DIR):\n",
    "            break\n",
    "\n",
    "    if group_name is None or os.path.getsize(orig_path) == 0:\n",
    "        continue\n",
    "\n",
    "    valid_paths.append(orig_path)\n",
    "    valid_labels.append(classes[group_name])\n",
    "\n",
    "# Her sınıftan 300 örnek seç\n",
    "random.seed(42)\n",
    "limited_paths, limited_labels = [], []\n",
    "for cls_name, cls_idx in classes.items():\n",
    "    cls_indices = [i for i, lab in enumerate(valid_labels) if lab == cls_idx]\n",
    "    selected = random.sample(cls_indices, min(len(cls_indices), 300))\n",
    "    for idx in selected:\n",
    "        limited_paths.append(valid_paths[idx])\n",
    "        limited_labels.append(cls_idx)\n",
    "\n",
    "# Train/Val/Test split\n",
    "paths_trainval, paths_test, labels_trainval, labels_test = train_test_split(\n",
    "    limited_paths, limited_labels, test_size=0.10, stratify=limited_labels, random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Eğitim Parametreleri\n",
    "# ---------------------------------------\n",
    "K = 2  # 2 fold\n",
    "num_epochs = 20  # Her fold için 20 epoch\n",
    "num_workers = 4\n",
    "PATCH_SIZE = 112\n",
    "\n",
    "# Sonuçları kaydetmek için klasör oluştur\n",
    "results_dir = f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Dataset Sınıfı\n",
    "# ---------------------------------------\n",
    "class ADNI_Dataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.cache = {}\n",
    "        self.max_cache_size = 100\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            if idx in self.cache:\n",
    "                return self.cache[idx]\n",
    "\n",
    "            full_path = self.paths[idx]\n",
    "            img_nib = nib.load(full_path)\n",
    "            img = img_nib.get_fdata().astype(np.float32)\n",
    "\n",
    "            # Normalize\n",
    "            p1, p99 = np.percentile(img, (1, 99))\n",
    "            img = np.clip(img, p1, p99)\n",
    "            img = (img - p1) / (p99 - p1 + 1e-6)\n",
    "\n",
    "            # Brain mask\n",
    "            thresh = threshold_otsu(img)\n",
    "            brain_mask = img > thresh\n",
    "            brain_mask = ndimage.binary_closing(brain_mask, structure=np.ones((3, 3, 3)))\n",
    "            brain_mask = ndimage.binary_fill_holes(brain_mask)\n",
    "            brain_mask = ndimage.binary_dilation(brain_mask, structure=np.ones((3, 3, 3)))\n",
    "\n",
    "            # Largest connected component\n",
    "            labeled, num_features = ndimage.label(brain_mask)\n",
    "            if num_features > 1:\n",
    "                counts = np.bincount(labeled.ravel())\n",
    "                counts[0] = 0\n",
    "                largest_label = counts.argmax()\n",
    "                brain_mask = (labeled == largest_label)\n",
    "\n",
    "            # Bounding box\n",
    "            coords = np.array(np.where(brain_mask))\n",
    "            if len(coords) == 0 or coords.size == 0:\n",
    "                raise ValueError(\"Empty coordinate array\")\n",
    "            \n",
    "            z_min, y_min, x_min = coords.min(axis=1)\n",
    "            z_max, y_max, x_max = coords.max(axis=1)\n",
    "\n",
    "            # Center crop\n",
    "            center_d = (z_min + z_max) // 2\n",
    "            center_h = (y_min + y_max) // 2\n",
    "            center_w = (x_min + x_max) // 2\n",
    "\n",
    "            half = PATCH_SIZE // 2\n",
    "            start_d = max(0, center_d - half)\n",
    "            start_h = max(0, center_h - half)\n",
    "            start_w = max(0, center_w - half)\n",
    "\n",
    "            d, h, w = img.shape\n",
    "            end_d = min(d, start_d + PATCH_SIZE)\n",
    "            end_h = min(h, start_h + PATCH_SIZE)\n",
    "            end_w = min(w, start_w + PATCH_SIZE)\n",
    "\n",
    "            # Adjust sizes\n",
    "            if end_d - start_d < PATCH_SIZE:\n",
    "                start_d = max(0, end_d - PATCH_SIZE)\n",
    "            if end_h - start_h < PATCH_SIZE:\n",
    "                start_h = max(0, end_h - PATCH_SIZE)\n",
    "            if end_w - start_w < PATCH_SIZE:\n",
    "                start_w = max(0, end_w - PATCH_SIZE)\n",
    "\n",
    "            patch = img[start_d:end_d, start_h:end_h, start_w:end_w]\n",
    "\n",
    "            # Padding\n",
    "            if patch.shape != (PATCH_SIZE, PATCH_SIZE, PATCH_SIZE):\n",
    "                padded = np.zeros((PATCH_SIZE, PATCH_SIZE, PATCH_SIZE), dtype=np.float32)\n",
    "                pd_, ph_, pw_ = patch.shape\n",
    "                sd = (PATCH_SIZE - pd_) // 2\n",
    "                sh = (PATCH_SIZE - ph_) // 2\n",
    "                sw = (PATCH_SIZE - pw_) // 2\n",
    "                padded[sd:sd+pd_, sh:sh+ph_, sw:sw+pw_] = patch\n",
    "                patch = padded\n",
    "\n",
    "            # Z-score normalize\n",
    "            mean = patch.mean()\n",
    "            std = patch.std() + 1e-6\n",
    "            patch = (patch - mean) / std\n",
    "\n",
    "            img_tensor = torch.from_numpy(patch).unsqueeze(0)\n",
    "            if self.transform:\n",
    "                img_tensor = self.transform(img_tensor)\n",
    "\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "            # Cache\n",
    "            if len(self.cache) >= self.max_cache_size:\n",
    "                self.cache.pop(next(iter(self.cache)))\n",
    "            self.cache[idx] = (img_tensor, label)\n",
    "\n",
    "            return img_tensor, label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {self.paths[idx]}: {str(e)}\")\n",
    "            return torch.zeros((1, PATCH_SIZE, PATCH_SIZE, PATCH_SIZE)), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Model Sınıfları\n",
    "# ---------------------------------------\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, d, h, w = x.size()\n",
    "        y = x.view(b, c, -1).mean(dim=2)\n",
    "        y = self.relu(self.fc1(y))\n",
    "        y = self.sigmoid(self.fc2(y))\n",
    "        y = y.view(b, c, 1, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class Inception3D_SE(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3reduce, ch3x3, ch5x5reduce, ch5x5, pool_proj):\n",
    "        super().__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, ch1x1, kernel_size=1, bias=False),\n",
    "            nn.InstanceNorm3d(ch1x1, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, ch3x3reduce, kernel_size=1, bias=False),\n",
    "            nn.InstanceNorm3d(ch3x3reduce, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(ch3x3reduce, ch3x3, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm3d(ch3x3, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.branch5 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, ch5x5reduce, kernel_size=1, bias=False),\n",
    "            nn.InstanceNorm3d(ch5x5reduce, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(ch5x5reduce, ch5x5, kernel_size=5, padding=2, bias=False),\n",
    "            nn.InstanceNorm3d(ch5x5, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv3d(in_channels, pool_proj, kernel_size=1, bias=False),\n",
    "            nn.InstanceNorm3d(pool_proj, affine=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        out_channels = ch1x1 + ch3x3 + ch5x5 + pool_proj\n",
    "        self.se = SEBlock(out_channels, reduction=16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b3 = self.branch3(x)\n",
    "        b5 = self.branch5(x)\n",
    "        bp = self.branch_pool(x)\n",
    "        out = torch.cat([b1, b3, b5, bp], dim=1)\n",
    "        out = self.se(out)\n",
    "        return out\n",
    "\n",
    "class Inception3DNet_SE(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.InstanceNorm3d(64, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=1, bias=False),\n",
    "            nn.InstanceNorm3d(64, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(64, 192, kernel_size=3, padding=1, bias=False),\n",
    "            nn.InstanceNorm3d(192, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.inception3a = Inception3D_SE(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception3D_SE(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception3c = Inception3D_SE(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception3d = Inception3D_SE(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception3e = Inception3D_SE(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.maxpool4 = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.dropout = nn.Dropout3d(p=dropout)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.InstanceNorm3d, nn.GroupNorm)):\n",
    "                if hasattr(m, 'weight') and m.weight is not None:\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                if hasattr(m, 'bias') and m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception3c(x)\n",
    "        x = self.inception3d(x)\n",
    "        x = self.inception3e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "# ---------------------------------------\n",
    "# Eğitim Fonksiyonları\n",
    "# ---------------------------------------\n",
    "def train_fold(fold, paths_train, labels_train, paths_val, labels_val, hyperparams, fold_results):\n",
    "    print(f\"\\n===== Fold {fold}/{K} =====\")\n",
    "    print(f\"Hyperparameters: {hyperparams}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    train_ds = ADNI_Dataset(paths_train, labels_train, transform=None)\n",
    "    val_ds = ADNI_Dataset(paths_val, labels_val, transform=None)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        prefetch_factor=2,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    \n",
    "    model = Inception3DNet_SE(num_classes=3, dropout=hyperparams['dropout']).to(DEVICE)\n",
    "    cls_loss_fn = CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=hyperparams['lr'], \n",
    "        weight_decay=hyperparams['weight_decay']\n",
    "    )\n",
    "    use_amp = (DEVICE.type == 'cuda')\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=True,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_path = os.path.join(results_dir, f'best_model_fold{fold}.pth')\n",
    "    fold_history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            try:\n",
    "                imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "                labels = labels.to(DEVICE, non_blocking=True)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with autocast(device_type=DEVICE.type, enabled=use_amp):\n",
    "                    logits = model(imgs)\n",
    "                    loss = cls_loss_fn(logits, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                preds = logits.argmax(dim=1)\n",
    "                train_correct += (preds == labels).sum().item()\n",
    "                train_total += labels.size(0)\n",
    "                \n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    print(f\"GPU bellek hatası: {str(e)}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                try:\n",
    "                    imgs = imgs.to(DEVICE)\n",
    "                    labels = labels.to(DEVICE)\n",
    "                    with autocast(device_type=DEVICE.type, enabled=use_amp):\n",
    "                        logits = model(imgs)\n",
    "                        loss = cls_loss_fn(logits, labels)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    preds_val = logits.argmax(dim=1)\n",
    "                    correct_val += (preds_val == labels).sum().item()\n",
    "                    total_val += labels.size(0)\n",
    "                    \n",
    "                    all_preds.extend(preds_val.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    \n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        print(f\"GPU bellek hatası: {str(e)}\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise e\n",
    "        \n",
    "        val_acc = correct_val / total_val\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Metrikleri kaydet\n",
    "        fold_history['train_loss'].append(avg_train_loss)\n",
    "        fold_history['train_acc'].append(train_acc)\n",
    "        fold_history['val_loss'].append(avg_val_loss)\n",
    "        fold_history['val_acc'].append(val_acc)\n",
    "        fold_history['learning_rates'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{num_epochs} - \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # En iyi modeli kaydet\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'hyperparams': hyperparams\n",
    "            }, best_model_path)\n",
    "            \n",
    "            # Confusion matrix ve classification report\n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            report = classification_report(all_labels, all_preds, target_names=[\"CN\",\"MCI\",\"AD\"], output_dict=True)\n",
    "            \n",
    "            # Sonuçları kaydet\n",
    "            fold_results[fold] = {\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'confusion_matrix': cm,\n",
    "                'classification_report': report,\n",
    "                'history': fold_history,\n",
    "                'hyperparams': hyperparams,\n",
    "                'true': all_labels,\n",
    "                'predicted': all_preds\n",
    "            }\n",
    "            \n",
    "            # Confusion matrix'i görselleştir ve kaydet\n",
    "            plt.figure(figsize=(8,6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', xticklabels=[\"CN\",\"MCI\",\"AD\"], yticklabels=[\"CN\",\"MCI\",\"AD\"])\n",
    "            plt.title(f\"Fold {fold} Confusion Matrix (Best Val Acc: {best_val_acc:.4f})\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.savefig(os.path.join(results_dir, f'confusion_matrix_fold{fold}.png'))\n",
    "            plt.close()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "def optimize_hyperparams(fold_results):\n",
    "    \"\"\"Fold sonuçlarına göre hiperparametreleri optimize et\"\"\"\n",
    "    if not fold_results:\n",
    "        return {\n",
    "            'lr': 1e-4,\n",
    "            'batch_size': 4,\n",
    "            'weight_decay': 1e-4,\n",
    "            'dropout': 0.3\n",
    "        }\n",
    "    \n",
    "    prev_fold = list(fold_results.keys())[-1]\n",
    "    prev_results = fold_results[prev_fold]\n",
    "    val_acc = prev_results['best_val_acc']\n",
    "    prev_params = prev_results['hyperparams']\n",
    "    \n",
    "    new_params = prev_params.copy()\n",
    "    \n",
    "    if val_acc < 0.7:\n",
    "        new_params['lr'] *= 1.5\n",
    "        new_params['dropout'] = min(0.5, new_params['dropout'] + 0.1)\n",
    "    elif val_acc > 0.85:\n",
    "        new_params['lr'] *= 0.8\n",
    "        new_params['weight_decay'] *= 1.2\n",
    "    \n",
    "    if val_acc < 0.75:\n",
    "        new_params['batch_size'] = max(2, new_params['batch_size'] - 2)\n",
    "    else:\n",
    "        new_params['batch_size'] = min(8, new_params['batch_size'] + 2)\n",
    "    \n",
    "    print(f\"\\nHyperparameter optimization:\")\n",
    "    print(f\"Previous fold val_acc: {val_acc:.4f}\")\n",
    "    print(\"Previous params:\", prev_params)\n",
    "    print(\"New params:\", new_params)\n",
    "    \n",
    "    return new_params\n",
    "\n",
    "# ---------------------------------------\n",
    "# Ana Eğitim Döngüsü\n",
    "# ---------------------------------------\n",
    "print(\"\\nStarting training...\")\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
    "fold_results = {}\n",
    "current_hyperparams = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(paths_trainval, labels_trainval), 1):\n",
    "    paths_train = [paths_trainval[i] for i in train_idx]\n",
    "    labels_train = [labels_trainval[i] for i in train_idx]\n",
    "    paths_val = [paths_trainval[i] for i in val_idx]\n",
    "    labels_val = [labels_trainval[i] for i in val_idx]\n",
    "    \n",
    "    current_hyperparams = optimize_hyperparams(fold_results)\n",
    "    fold_results = train_fold(fold, paths_train, labels_train, paths_val, labels_val, \n",
    "                            current_hyperparams, fold_results)\n",
    "    \n",
    "    with open(os.path.join(results_dir, f'fold{fold}_results.txt'), 'w') as f:\n",
    "        f.write(f\"Fold {fold} Results:\\n\")\n",
    "        f.write(f\"Best Validation Accuracy: {fold_results[fold]['best_val_acc']:.4f}\\n\")\n",
    "        f.write(f\"Hyperparameters: {fold_results[fold]['hyperparams']}\\n\\n\")\n",
    "        f.write(\"Classification Report:\\n\")\n",
    "        f.write(classification_report(\n",
    "            fold_results[fold]['true'],\n",
    "            fold_results[fold]['predicted'],\n",
    "            target_names=[\"CN\",\"MCI\",\"AD\"]\n",
    "        ))\n",
    "\n",
    "# Final sonuçları\n",
    "print(\"\\n===== Final Results =====\")\n",
    "for fold in fold_results:\n",
    "    print(f\"\\nFold {fold}:\")\n",
    "    print(f\"Best Validation Accuracy: {fold_results[fold]['best_val_acc']:.4f}\")\n",
    "    print(\"Hyperparameters:\", fold_results[fold]['hyperparams'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        fold_results[fold]['true'],\n",
    "        fold_results[fold]['predicted'],\n",
    "        target_names=[\"CN\",\"MCI\",\"AD\"]\n",
    "    ))\n",
    "\n",
    "# Sonuçları görselleştir\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Training ve validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "for fold in fold_results:\n",
    "    plt.plot(fold_results[fold]['history']['train_loss'], label=f'Train (Fold {fold})')\n",
    "    plt.plot(fold_results[fold]['history']['val_loss'], label=f'Val (Fold {fold})')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Training ve validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "for fold in fold_results:\n",
    "    plt.plot(fold_results[fold]['history']['train_acc'], label=f'Train (Fold {fold})')\n",
    "    plt.plot(fold_results[fold]['history']['val_acc'], label=f'Val (Fold {fold})')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'training_history.png'))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nResults saved in directory: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7573050,
     "sourceId": 12036252,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42623.959723,
   "end_time": "2025-06-11T19:24:29.552048",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-11T07:34:05.592325",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
